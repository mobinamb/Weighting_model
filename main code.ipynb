{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2 \n",
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from datetime import datetime\n",
    "import xlsxwriter\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#compensate for data imbalance\n",
    "from sklearn.utils import shuffle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "EPOCHS =20\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 64\n",
    "meanDataset =[0.4415734549019608,0.388225627197976,0.3462771010120177]\n",
    "stdDataset =[0.2711501212166684,0.24437697540137235,0.2350548283233844]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function you need to use to remove the classifier layer\n",
    "class Identity(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "\n",
    "def ResizedTensor(image, size): # the function to resize the images to the desired size\n",
    "\n",
    "    dim=size\n",
    "    resized = cv2.resize(image, dim, interpolation =  cv2.INTER_LINEAR )\n",
    "    #print(resized.shape)\n",
    "    return resized\n",
    "\n",
    "def CenterCropTensor(image, size): # the function to to do center crop\n",
    "\n",
    "    image_width, image_height, channel = image.shape\n",
    "\n",
    "    #image_width, image_height = _get_image_size(img)\n",
    "    crop_height, crop_width = size\n",
    "\n",
    "    # crop_top = int(round((image_height - crop_height) / 2.))\n",
    "    # Result can be different between python func and scripted func\n",
    "    # Temporary workaround:\n",
    "    crop_top = int((image_height - crop_height + 1) * 0.5)\n",
    "    # crop_left = int(round((image_width - crop_width) / 2.))\n",
    "    # Result can be different between python func and scripted func\n",
    "    # Temporary workaround:\n",
    "    crop_left = int((image_width - crop_width + 1) * 0.5)\n",
    "    img=image[ crop_left: crop_left+crop_width,crop_top:crop_top+crop_height,:];\n",
    "    return img #crop(img, crop_top, crop_left, crop_height, crop_width)\n",
    "\n",
    "def preprocess(image):\n",
    "\n",
    "    masked  =  image / 255 \n",
    "\n",
    "    for ch in range (0,3):\n",
    "        masked[:,:,ch]=(masked[:,:,ch]-meanDataset[ch])/stdDataset[ch]\n",
    "        \n",
    "    masked=ResizedTensor(masked,(256,256))\n",
    "    masked=CenterCropTensor(masked,(224,224))\n",
    "\n",
    "\n",
    "    masked=torch.tensor(masked).permute(2, 0, 1).unsqueeze(0).to(device, dtype=torch.float)  #this part move the image from CPU to GPU\n",
    "    return masked\n",
    "\n",
    "## train data\n",
    "class TrainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "                 \n",
    "## test data    \n",
    "class TestData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "class BinaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassification, self).__init__()\n",
    "        # Number of input features is 12.\n",
    "        self.layer_1 = nn.Linear(4096, 64) \n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(64, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs)) \n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        #x = self.dropout(x)\n",
    "        x = self.layer_out(x) \n",
    "        x=torch.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(y_pred)\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dataset\n",
    "dataset_dic={'unmasked_image_path':[],'masked_positive_path':[],'masked_negative_path':[]} # masked positive doesn't include the same masked image of the input unmasked image\n",
    "root_unmasked='dataset/unmasked_attached'\n",
    "root_masked='dataset/masked_attached'\n",
    "unmasked_images=os.listdir(root_unmasked)\n",
    "masked_images=os.listdir(root_masked)\n",
    "\n",
    "for i in range(len(unmasked_images)):\n",
    "    dataset_dic['unmasked_image_path'].append(root_unmasked+'/'+unmasked_images[i])\n",
    "    pos,neg=[],[]\n",
    "    for j in range(len(masked_images)):\n",
    "        if (unmasked_images[i].split('_')[0]+'_'+unmasked_images[i].split('_')[1]== masked_images[j].split('_')[0]+'_'+masked_images[j].split('_')[1] and unmasked_images[i]!=masked_images[j][:-9] ):\n",
    "            pos.append(root_masked+'/'+masked_images[j])\n",
    "        elif (unmasked_images[i].split('_')[0]+'_'+unmasked_images[i].split('_')[1]!= masked_images[j].split('_')[0]+'_'+masked_images[j].split('_')[1]):\n",
    "            neg.append(root_masked+'/'+masked_images[j])\n",
    "    dataset_dic['masked_positive_path'].append(pos)\n",
    "    dataset_dic['masked_negative_path'].append(neg)\n",
    "\n",
    "#model with no classifier (feature extractor)\n",
    "model=torch.load('modelWithBestValidationAcc_unmasked_100epochs_v2.h5').eval()\n",
    "model.classifier[6]=Identity()\n",
    "model.fc=Identity()\n",
    "model.to(device).eval() #put the model on GPU\n",
    "\n",
    "data={} # this is the final dictionay of the dataset \n",
    "count=1\n",
    "if True:\n",
    "    for i in range(100):\n",
    "        ff,ff_p,ff_n=[],[],[]\n",
    "        #print(dataset_dic['unmasked_image_path'][i])\n",
    "        unmasked_imagee=cv2.imread(dataset_dic['unmasked_image_path'][i])\n",
    "        processed_unmasked_image=preprocess(unmasked_imagee)\n",
    "        f=model(processed_unmasked_image).cpu().detach().numpy()\n",
    "        f_norm=f/np.sqrt(np.dot(f,np.transpose(f)))\n",
    "        for j in range(5):\n",
    "             #print(dataset_dic['masked_positive_path'][i][j])\n",
    "             masked_image_pos=cv2.imread(dataset_dic['masked_positive_path'][i][j])\n",
    "             processed_masked_image_pos=preprocess(masked_image_pos)\n",
    "             f_p=model(processed_masked_image_pos).cpu().detach().numpy()\n",
    "             f_p_norm=f_p/np.sqrt(np.dot(f_p,np.transpose(f_p)))\n",
    "             A=f_norm-f_p_norm\n",
    "             dic={}\n",
    "             for kk in range(len(A[0])):\n",
    "                dic[str(kk+1)]=A[0][kk]\n",
    "             dic['s_d']='same'\n",
    "             data.update({str(count):dic})\n",
    "             count+=1\n",
    "\n",
    "        for k in range(5):\n",
    "             masked_image_neg=cv2.imread(dataset_dic['masked_negative_path'][i][k])\n",
    "             processed_masked_image_neg=preprocess(masked_image_neg)\n",
    "             f_n=model(processed_masked_image_neg).cpu().detach().numpy()\n",
    "             f_n_norm=f/np.sqrt(np.dot(f_n,np.transpose(f_n)))\n",
    "             B=f_norm-f_n_norm\n",
    "             dic={}\n",
    "             for kkk in range(len(B[0])):\n",
    "                dic[str(kkk+1)]=B[0][kkk]\n",
    "             dic['s_d']='different'\n",
    "             data.update({str(count):dic})\n",
    "             count+=1\n",
    "\n",
    "df=pd.DataFrame(data).transpose()\n",
    "df = shuffle(df)\n",
    "\n",
    "df['s_d'] = df['s_d'].astype('category')\n",
    "encode_map = {\n",
    "    'same': 1,\n",
    "    'different': 0\n",
    "}\n",
    "\n",
    "df['s_d'].replace(encode_map, inplace=True)\n",
    "\n",
    "# condition with df.values property\n",
    "'''same= df['s_d'].values == 1\n",
    "different= df['s_d'].values == 0\n",
    "# new dataframe\n",
    "df_same = df[same]\n",
    "df_different1=df[different]\n",
    "df_different=df_different1.iloc[:1596,:] # this is to create a balanced dataset since we had 1596 cases of the \"same\" class, we got 1596 of the \"different\" class and combine them\n",
    "frames=[df_same,df_different]\n",
    "result = pd.concat(frames)''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing the data\n",
    "result=shuffle(df)\n",
    "X = result.iloc[:, 0:-1]\n",
    "y = result.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "train_data = TrainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "      \n",
    "test_data = TestData(torch.FloatTensor(X_test))\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryClassification(\n",
      "  (layer_1): Linear(in_features=4096, out_features=64, bias=True)\n",
      "  (layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (layer_out): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Epoch 001: | Loss: 0.60967 | Acc: 89.636\n",
      "Epoch 002: | Loss: 0.54477 | Acc: 97.182\n",
      "Epoch 003: | Loss: 0.52549 | Acc: 99.091\n",
      "Epoch 004: | Loss: 0.51231 | Acc: 100.000\n",
      "Epoch 005: | Loss: 0.50815 | Acc: 100.000\n",
      "Epoch 006: | Loss: 0.51033 | Acc: 100.000\n",
      "Epoch 007: | Loss: 0.50555 | Acc: 100.000\n",
      "Epoch 008: | Loss: 0.50431 | Acc: 100.000\n",
      "Epoch 009: | Loss: 0.50674 | Acc: 100.000\n",
      "Epoch 010: | Loss: 0.50489 | Acc: 100.000\n",
      "Epoch 011: | Loss: 0.50385 | Acc: 100.000\n",
      "Epoch 012: | Loss: 0.50774 | Acc: 100.000\n",
      "Epoch 013: | Loss: 0.50618 | Acc: 100.000\n",
      "Epoch 014: | Loss: 0.50329 | Acc: 100.000\n",
      "Epoch 015: | Loss: 0.50998 | Acc: 100.000\n",
      "Epoch 016: | Loss: 0.51066 | Acc: 98.636\n",
      "Epoch 017: | Loss: 0.50476 | Acc: 100.000\n",
      "Epoch 018: | Loss: 0.50271 | Acc: 99.818\n",
      "Epoch 019: | Loss: 0.50406 | Acc: 100.000\n",
      "Epoch 020: | Loss: 0.50597 | Acc: 100.000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       167\n",
      "           1       1.00      1.00      1.00       163\n",
      "\n",
      "    accuracy                           1.00       330\n",
      "   macro avg       1.00      1.00      1.00       330\n",
      "weighted avg       1.00      1.00      1.00       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#weighting model\n",
    "model = BinaryClassification()\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "\n",
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        #y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "\n",
    "confusion_matrix(y_test, y_pred_list)\n",
    "print(classification_report(y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'classification_model.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d17f44f4d285859fbe37bc4ef85a3a55bc66f314eb39f44e95d2173affd3a8f"
  },
  "kernelspec": {
   "display_name": "Python 3.6.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
